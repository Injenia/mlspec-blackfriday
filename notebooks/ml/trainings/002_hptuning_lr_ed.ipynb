{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e8590f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from oauth2client.client import GoogleCredentials\n",
    "from googleapiclient import discovery\n",
    "from googleapiclient import errors\n",
    "import tensorflow as tf\n",
    "import tensorflow_recommenders as tfrs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas(leave=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc778905",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129d89da",
   "metadata": {},
   "source": [
    "## configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "279d04b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT             = \"mlteam-ml-specialization-2021\"\n",
    "TRAIN_PATH          = \"gs://mlteam-ml-specialization-2021-blackfriday/dataset/parsed/202104130952/train.csv\"\n",
    "TEST_PATH           = \"gs://mlteam-ml-specialization-2021-blackfriday/dataset/parsed/202104130952/test.csv\"\n",
    "MODEL_NAME          = \"002_hptuning_lr_ed\"\n",
    "BATCH_SIZE          = 30000 #1 epoch -> 3 steps\n",
    "NUM_EPOCHS          = 1500\n",
    "SCANN_NUM_NEIGHBORS = 10\n",
    "#LEARNING_RATE       = 0.01\n",
    "#EMBEDDING_DIM       = 128\n",
    "USER_FEATURES       = [\"Gender\", \"Age\", \"Occupation\"]#, \"City_Category\", \"Stay_In_Current_City_Years\", \"Marital_Status\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c140c820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing config.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile config.yaml\n",
    "trainingInput:\n",
    "  hyperparameters:\n",
    "    goal: MINIMIZE\n",
    "    hyperparameterMetricTag: epoch_total_loss\n",
    "    maxTrials: 8\n",
    "    maxParallelTrials: 8\n",
    "    enableTrialEarlyStopping: False\n",
    "    params:\n",
    "    - parameterName: learning-rate\n",
    "      type: DISCRETE\n",
    "      discreteValues:\n",
    "      - 0.01\n",
    "      - 0.1\n",
    "    - parameterName: embedding-dim\n",
    "      type: DISCRETE\n",
    "      discreteValues:\n",
    "      - 8\n",
    "      - 32\n",
    "      - 128\n",
    "      - 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1279cbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = os.path.join(\"gs://mlteam-ml-specialization-2021-blackfriday/aiplatform_jobs\", MODEL_NAME)\n",
    "assert not tf.io.gfile.exists(MODEL_PATH), f\"{MODEL_PATH} already exists\"\n",
    "\n",
    "\n",
    "os.environ[\"TRAIN_PATH\"]          = str(TRAIN_PATH)\n",
    "os.environ[\"TEST_PATH\"]           = str(TEST_PATH)\n",
    "os.environ[\"MODEL_NAME\"]          = str(MODEL_NAME)\n",
    "os.environ[\"MODEL_PATH\"]          = str(MODEL_PATH)\n",
    "os.environ[\"BATCH_SIZE\"]          = str(BATCH_SIZE)\n",
    "os.environ[\"NUM_EPOCHS\"]          = str(NUM_EPOCHS)\n",
    "os.environ[\"SCANN_NUM_NEIGHBORS\"] = str(SCANN_NUM_NEIGHBORS)\n",
    "#os.environ[\"LEARNING_RATE\"]       = str(LEARNING_RATE)\n",
    "#os.environ[\"EMBEDDING_DIM\"]       = str(EMBEDDING_DIM)\n",
    "os.environ[\"USER_FEATURES\"]       = json.dumps(USER_FEATURES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370931d9",
   "metadata": {},
   "source": [
    "## launch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4da48bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jobId: bf_002_hptuning_lr_ed_20210526_160313\n",
      "state: QUEUED\n",
      "createTime: '2021-05-26T16:03:16Z'\n",
      "etag: WGI_mQ34igI=\n",
      "jobId: bf_002_hptuning_lr_ed_20210526_160313\n",
      "state: PREPARING\n",
      "trainingInput:\n",
      "  args:\n",
      "  - --train-path=gs://mlteam-ml-specialization-2021-blackfriday/dataset/parsed/202104130952/train.csv\n",
      "  - --job-dir=gs://mlteam-ml-specialization-2021-blackfriday/aiplatform_jobs/002_hptuning_lr_ed\n",
      "  - --num-epochs=1500\n",
      "  - --batch-size=30000\n",
      "  - --scann-num-neighbors=10\n",
      "  - --user-features=[\"Gender\", \"Age\", \"Occupation\"]\n",
      "  hyperparameters:\n",
      "    goal: MINIMIZE\n",
      "    hyperparameterMetricTag: epoch_total_loss\n",
      "    maxParallelTrials: 8\n",
      "    maxTrials: 8\n",
      "    params:\n",
      "    - discreteValues:\n",
      "      - 0.01\n",
      "      - 0.1\n",
      "      parameterName: learning-rate\n",
      "      type: DISCRETE\n",
      "    - discreteValues:\n",
      "      - 8.0\n",
      "      - 32.0\n",
      "      - 128.0\n",
      "      - 512.0\n",
      "      parameterName: embedding-dim\n",
      "      type: DISCRETE\n",
      "  jobDir: gs://mlteam-ml-specialization-2021-blackfriday/aiplatform_jobs/002_hptuning_lr_ed\n",
      "  packageUris:\n",
      "  - gs://mlteam-ml-specialization-2021-blackfriday/aiplatform_jobs/002_hptuning_lr_ed/packages/adc6e2b6f74ed0378df6695f1418b9fe6fa149cf87d3fb58843e980d7cb4dfa3/mlspec-blackfriday-0.1.tar.gz\n",
      "  pythonModule: trainer.task\n",
      "  pythonVersion: '3.7'\n",
      "  region: europe-west1\n",
      "  runtimeVersion: '2.4'\n",
      "trainingOutput:\n",
      "  isHyperparameterTuningJob: true\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Job [bf_002_hptuning_lr_ed_20210526_160313] submitted successfully.\n",
      "Your job is still active. You may view the status of your job with the command\n",
      "\n",
      "  $ gcloud ai-platform jobs describe bf_002_hptuning_lr_ed_20210526_160313\n",
      "\n",
      "or continue streaming the logs with the command\n",
      "\n",
      "  $ gcloud ai-platform jobs stream-logs bf_002_hptuning_lr_ed_20210526_160313\n",
      "\n",
      "View job in the Cloud Console at:\n",
      "https://console.cloud.google.com/mlengine/jobs/bf_002_hptuning_lr_ed_20210526_160313?project=mlteam-ml-specialization-2021\n",
      "\n",
      "View logs at:\n",
      "https://console.cloud.google.com/logs?resource=ml_job%2Fjob_id%2Fbf_002_hptuning_lr_ed_20210526_160313&project=mlteam-ml-specialization-2021\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "# JOB_NAME: the name of your job running on AI Platform.\n",
    "JOB_NAME=bf_${MODEL_NAME}_$(date +%Y%m%d_%H%M%S)\n",
    "\n",
    "# REGION: select a region from https://cloud.google.com/ai-platform/training/docs/regions\n",
    "# or use the default '`us-central1`'. The region is where the model will be deployed.\n",
    "REGION=europe-west1\n",
    "PYTHON_VERSION=3.7\n",
    "RUNTIME_VERSION=2.4\n",
    "\n",
    "current_dir=\"$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" >/dev/null 2>&1 && pwd)\"\n",
    "cd ${current_dir}\"/../../..\"\n",
    "\n",
    "config_file=\"${current_dir}/config.yaml\"\n",
    "\n",
    "gcloud ai-platform jobs submit training \"${JOB_NAME}\" \\\n",
    "  --package-path trainer/ \\\n",
    "  --module-name trainer.task \\\n",
    "  --region ${REGION} \\\n",
    "  --python-version ${PYTHON_VERSION} \\\n",
    "  --runtime-version ${RUNTIME_VERSION} \\\n",
    "  --job-dir \"${MODEL_PATH}\" \\\n",
    "  --config \"${config_file}\" \\\n",
    "  -- \\\n",
    "  --train-path=\"${TRAIN_PATH}\" \\\n",
    "  --job-dir=\"${MODEL_PATH}\" \\\n",
    "  --num-epochs=${NUM_EPOCHS} \\\n",
    "  --batch-size=${BATCH_SIZE} \\\n",
    "  --scann-num-neighbors=${SCANN_NUM_NEIGHBORS} \\\n",
    "  --user-features=\"${USER_FEATURES}\"\n",
    "\n",
    "#  --learning-rate=${LEARNING_RATE} \\\n",
    "#  --embedding-dim=${EMBEDDING_DIM} \\\n",
    "\n",
    "gcloud ai-platform jobs describe ${JOB_NAME}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac1a3af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf config.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c19cec2",
   "metadata": {},
   "source": [
    "### now wait for job completion...."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69724ad9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f152a0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_path = os.path.join(\"gs://mlteam-ml-specialization-2021-blackfriday/aiplatform_jobs\", MODEL_NAME, \"metadata.json\")\n",
    "\n",
    "ml               = discovery.build('ml','v1')\n",
    "projectId        = 'projects/{}'.format(PROJECT)\n",
    "ai_platform_data = ml.projects().jobs().list(parent=projectId).execute()\n",
    "jobs             = ai_platform_data[\"jobs\"]\n",
    "latest_job       = sorted([j for j in jobs if j['jobId'].startswith(f\"bf_{MODEL_NAME}\")], key=lambda x: x[\"jobId\"])[-1]\n",
    "if latest_job[\"trainingOutput\"].get('isHyperparameterTuningJob',None) is not None:\n",
    "    trials = latest_job[\"trainingOutput\"][\"trials\"]\n",
    "    json.dump(trials, tf.io.gfile.GFile(metadata_path, \"w\"))\n",
    "else:\n",
    "    metadata = [{\n",
    "        'trialId'        : '1',\n",
    "        'hyperparameters': {},\n",
    "        'startTime'      : latest_job[\"startTime\"],\n",
    "        'endTime'        : latest_job[\"endTime\"],\n",
    "        'state'          : latest_job[\"state\"],\n",
    "    }]\n",
    "    json.dump(metadata, tf.io.gfile.GFile(metadata_path, \"w\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75ec5cd",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2acc6906",
   "metadata": {},
   "source": [
    "## ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fc0694",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_USER_FEATURES   = [\"Gender\", \"Age\", \"Occupation\", \"City_Category\", \"Stay_In_Current_City_Years\", \"Marital_Status\"] \n",
    "\n",
    "df=pd.read_csv(TEST_PATH).groupby(ALL_USER_FEATURES)[\"Product_ID\"].apply(list).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12653072",
   "metadata": {},
   "source": [
    "## baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d459ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlackFridayBaseline:\n",
    "    def __init__(self, trainset_location, user_features_list, build_inplace=False):\n",
    "        self.trainset_location, self.user_features_list = trainset_location, user_features_list\n",
    "        if build_inplace:\n",
    "            self.build()\n",
    "        \n",
    "    def build(self):\n",
    "        self.df = pd.read_csv(self.trainset_location).groupby(\n",
    "            self.user_features_list+[\"Product_ID\"])[\"User_ID\"].count().reset_index().rename(\n",
    "            columns={\"User_ID\":\"count_product\"})\n",
    "        \n",
    "    def predict(self, user_features, n_products):\n",
    "        mask = None\n",
    "        for k,v in user_features.items():\n",
    "            if mask is None:\n",
    "                mask = self.df[k]==v\n",
    "            else:\n",
    "                mask = mask&(self.df[k]==v)\n",
    "        return self.df[mask].sort_values(self.user_features_list+[\"count_product\"])[\"Product_ID\"].values[:n_products]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5434a2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = BlackFridayBaseline(TRAIN_PATH, ALL_USER_FEATURES, True)\n",
    "df[\"baseline\"]=df[ALL_USER_FEATURES].progress_apply(lambda x: baseline.predict(x, SCANN_NUM_NEIGHBORS), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3ff8de",
   "metadata": {},
   "source": [
    "## model(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ab1c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PredictionModel:\n",
    "    def __init__(self, model_path, build_inplace=False):\n",
    "        self.model_path=model_path\n",
    "        if build_inplace:\n",
    "            self.build()\n",
    "    \n",
    "    def build(self):\n",
    "        self.model=tf.keras.models.load_model(self.model_path)\n",
    "        \n",
    "    def predict_batch(self, model_input):\n",
    "        scores, products = self.model({k:tf.constant(v) for k,v in model_input.items()})\n",
    "        return products.numpy()\n",
    "    \n",
    "    def predict_single(self, model_input):\n",
    "        scores, products = self.model({k:tf.constant([v]) for k,v in model_input.items()})\n",
    "        return products.numpy()\n",
    "    \n",
    "\n",
    "def evaluate_model(data_df, model, baseline_precision, title=\"\", figsize=(20,10)):\n",
    "    k_min = SCANN_NUM_NEIGHBORS\n",
    "    df=data_df.copy()\n",
    "    df[\"predictions\"]=df[USER_FEATURES].progress_apply(lambda x: model.predict_single({k:str(v) for k,v in x.items()})[0].astype(str), axis=1)\n",
    "    df_orig=df\n",
    "    df=df_orig[df_orig[\"Product_ID\"].apply(len) >= k_min]\n",
    "    df_metrics = pd.DataFrame(index=df.index)\n",
    "    df_metrics[\"baseline_precision\"]=baseline_precision\n",
    "    df_metrics[\"predictions_precision\"]=df[[\"Product_ID\",\"predictions\"]].progress_apply(lambda x: np.intersect1d(x[\"Product_ID\"],x[\"predictions\"]).shape[0]/k_min,axis=1)\n",
    "    pd.DataFrame([\n",
    "        df_metrics[\"baseline_precision\"].apply(lambda x: round(x,2)).value_counts(),\n",
    "        df_metrics[\"predictions_precision\"].apply(lambda x: round(x,2)).value_counts()\n",
    "    ]).transpose().fillna(0).plot.bar(figsize=figsize, title=title)\n",
    "    return df_metrics[[\"baseline_precision\",\"predictions_precision\"]].mean()    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264c0677",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "metadata_path = os.path.join(\"gs://mlteam-ml-specialization-2021-blackfriday/aiplatform_jobs\", MODEL_NAME, \"metadata.json\")\n",
    "metadata = json.load(tf.io.gfile.GFile(metadata_path, \"r\"))\n",
    "results = {}\n",
    "baseline_precision=df[\n",
    "    df[\"Product_ID\"].apply(len) >= SCANN_NUM_NEIGHBORS\n",
    "][\n",
    "    [\"Product_ID\",\"baseline\"]\n",
    "].progress_apply(\n",
    "    lambda x: np.intersect1d(x[\"Product_ID\"],x[\"baseline\"]).shape[0]/SCANN_NUM_NEIGHBORS,\n",
    "    axis=1\n",
    ")\n",
    "results[\"baseline\"] = {\"precision\":baseline_precision.mean()}\n",
    "for j in tqdm(metadata):\n",
    "    model = PredictionModel(os.path.join(\"gs://mlteam-ml-specialization-2021-blackfriday/aiplatform_jobs\", MODEL_NAME, j['trialId'], 'Scann'), True)\n",
    "    hps = json.dumps(j[\"hyperparameters\"])\n",
    "    res = evaluate_model(df, model, baseline_precision, title=f\"trial_{j['trialId']} - {hps}\")\n",
    "    #results[\"baseline\"]={\"precision\":res[\"baseline_precision\"]}\n",
    "    results[f\"trial_{j['trialId']}\"] = {\"precision\":res[\"predictions_precision\"], \"hyperparameters\": j[\"hyperparameters\"]}\n",
    "    \n",
    "pd.DataFrame(results).T.sort_values(by=\"precision\", ascending=False)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-3.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m65"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
