{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "665dfb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from oauth2client.client import GoogleCredentials\n",
    "from googleapiclient import discovery\n",
    "from googleapiclient import errors\n",
    "import tensorflow as tf\n",
    "import tensorflow_recommenders as tfrs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas(leave=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8f5fad",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0fad6db",
   "metadata": {},
   "source": [
    "## configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5571696",
   "metadata": {},
   "outputs": [],
   "source": [
    "GCS_ROOT                 = \"gs://mlteam-ml-specialization-2021-blackfriday/aiplatform_jobs\"\n",
    "PROJECT                  = \"mlteam-ml-specialization-2021\"\n",
    "TRAIN_PATH               = \"gs://mlteam-ml-specialization-2021-blackfriday/dataset/parsed/202104130952/train.csv\"\n",
    "EVAL_PATH                = \"gs://mlteam-ml-specialization-2021-blackfriday/dataset/parsed/202104130952/test/evalset.csv\"\n",
    "TEST_PATH                = \"gs://mlteam-ml-specialization-2021-blackfriday/dataset/parsed/202104130952/test/testset.csv\"\n",
    "RESUME_FROM              = \"012_hptuning_deep\"\n",
    "TRIAL_NUMBER             = \"1\"\n",
    "MODEL_NAME               = \"12_resume_training_sample\"\n",
    "BATCH_SIZE               = 30000 #1 epoch -> 3 steps\n",
    "NUM_EPOCHS               = 500\n",
    "SCANN_NUM_NEIGHBORS      = 100\n",
    "#LEARNING_RATE            = 0.01\n",
    "EMBEDDING_DIM            = 128\n",
    "USER_FEATURES            = [\"Gender\", \"Age\", \"Occupation\", \"City_Category\", \"Stay_In_Current_City_Years\", \"Marital_Status\"]\n",
    "#USER_INPUT_EMBEDDING_DIM = 8\n",
    "FORCE                    = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d976848",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "MODEL_PATH = os.path.join(GCS_ROOT, MODEL_NAME)\n",
    "os.environ[\"GCS_ROOT\"]                 = str(GCS_ROOT)\n",
    "os.environ[\"RESUME_FROM\"]              = str(RESUME_FROM)\n",
    "os.environ[\"TRIAL_NUMBER\"]             = str(TRIAL_NUMBER)\n",
    "os.environ[\"TRAIN_PATH\"]               = str(TRAIN_PATH)\n",
    "os.environ[\"EVAL_PATH\"]                = str(EVAL_PATH)\n",
    "os.environ[\"TEST_PATH\"]                = str(TEST_PATH)\n",
    "os.environ[\"MODEL_NAME\"]               = str(MODEL_NAME)\n",
    "os.environ[\"MODEL_PATH\"]               = str(MODEL_PATH)\n",
    "os.environ[\"BATCH_SIZE\"]               = str(BATCH_SIZE)\n",
    "os.environ[\"NUM_EPOCHS\"]               = str(NUM_EPOCHS)\n",
    "os.environ[\"SCANN_NUM_NEIGHBORS\"]      = str(SCANN_NUM_NEIGHBORS)\n",
    "os.environ[\"LEARNING_RATE\"]            = str(LEARNING_RATE)\n",
    "os.environ[\"EMBEDDING_DIM\"]            = str(EMBEDDING_DIM)\n",
    "os.environ[\"USER_INPUT_EMBEDDING_DIM\"] = str(USER_INPUT_EMBEDDING_DIM)\n",
    "os.environ[\"USER_FEATURES\"]            = json.dumps(USER_FEATURES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210cb54b",
   "metadata": {},
   "source": [
    "## launch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666c49ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil -m cp -r ${GCS_ROOT}/${RESUME_FROM}/${TRIAL_NUMBER} ${GCS_ROOT}/${MODEL_NAME}/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4427e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# JOB_NAME: the name of your job running on AI Platform.\n",
    "JOB_NAME=bf_${MODEL_NAME}_$(date +%Y%m%d_%H%M%S)\n",
    "\n",
    "# REGION: select a region from https://cloud.google.com/ai-platform/training/docs/regions\n",
    "# or use the default '`us-central1`'. The region is where the model will be deployed.\n",
    "REGION=europe-west1\n",
    "PYTHON_VERSION=3.7\n",
    "RUNTIME_VERSION=2.4\n",
    "\n",
    "current_dir=\"$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" >/dev/null 2>&1 && pwd)\"\n",
    "cd ${current_dir}\"/../../..\"\n",
    "\n",
    "gcloud ai-platform jobs submit training \"${JOB_NAME}\" \\\n",
    "  --package-path trainer/ \\\n",
    "  --module-name trainer.task \\\n",
    "  --region ${REGION} \\\n",
    "  --python-version ${PYTHON_VERSION} \\\n",
    "  --runtime-version ${RUNTIME_VERSION} \\\n",
    "  --job-dir \"${MODEL_PATH}\" \\\n",
    "  -- \\\n",
    "  --train-path=\"${TRAIN_PATH}\" \\\n",
    "  --eval-path=\"${EVAL_PATH}\" \\\n",
    "  --job-dir=\"${MODEL_PATH}\" \\\n",
    "  --batch-size=${BATCH_SIZE} \\\n",
    "  --scann-num-neighbors=${SCANN_NUM_NEIGHBORS} \\\n",
    "  --user-features=\"${USER_FEATURES}\" \\\n",
    "  --num-epochs=${NUM_EPOCHS} \\\n",
    "  --embedding-dim=${EMBEDDING_DIM} \\\n",
    "  --trial=${TRIAL_NUMBER}\n",
    "\n",
    "gcloud ai-platform jobs describe ${JOB_NAME}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5085bbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_path = os.path.join(\"gs://mlteam-ml-specialization-2021-blackfriday/aiplatform_jobs\", MODEL_NAME, \"metadata.json\")\n",
    "\n",
    "ml               = discovery.build('ml','v1')\n",
    "projectId        = 'projects/{}'.format(PROJECT)\n",
    "ai_platform_data = ml.projects().jobs().list(parent=projectId).execute()\n",
    "jobs             = ai_platform_data[\"jobs\"]\n",
    "latest_job       = sorted([j for j in jobs if j['jobId'].startswith(f\"bf_{MODEL_NAME}\")], key=lambda x: x[\"jobId\"])[-1]\n",
    "\n",
    "metadata = [{\n",
    "    'trialId'        : TRIAL_NUMBER,\n",
    "    'hyperparameters': {},\n",
    "    'startTime'      : latest_job[\"startTime\"],\n",
    "    'endTime'        : latest_job[\"endTime\"],\n",
    "    'state'          : latest_job[\"state\"],\n",
    "}]\n",
    "json.dump(metadata, tf.io.gfile.GFile(metadata_path, \"w\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a9e264",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113d6b83",
   "metadata": {},
   "source": [
    "## ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5ecff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_USER_FEATURES   = [\"Gender\", \"Age\", \"Occupation\", \"City_Category\", \"Stay_In_Current_City_Years\", \"Marital_Status\"] \n",
    "\n",
    "df = pd.read_csv(TEST_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ac78de",
   "metadata": {},
   "source": [
    "## baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6045a460",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlackFridayBaseline:\n",
    "    def __init__(self, trainset_location, user_features_list, build_inplace=False):\n",
    "        self.trainset_location, self.user_features_list = trainset_location, user_features_list\n",
    "        if build_inplace:\n",
    "            self.build()\n",
    "        \n",
    "    def build(self):\n",
    "        self.df = pd.read_csv(self.trainset_location).groupby(\n",
    "            self.user_features_list+[\"Product_ID\"])[\"User_ID\"].count().reset_index().rename(\n",
    "            columns={\"User_ID\":\"count_product\"})\n",
    "        \n",
    "    def predict(self, user_features, n_products):\n",
    "        mask = None\n",
    "        for k,v in user_features.items():\n",
    "            if mask is None:\n",
    "                mask = self.df[k]==v\n",
    "            else:\n",
    "                mask = mask&(self.df[k]==v)\n",
    "        return self.df[mask].sort_values(self.user_features_list+[\"count_product\"])[\"Product_ID\"].values[:n_products]\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9d1023",
   "metadata": {},
   "source": [
    "## model(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d1f49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PredictionModel:\n",
    "    def __init__(self, model_path, build_inplace=False):\n",
    "        self.model_path=model_path\n",
    "        if build_inplace:\n",
    "            self.build()\n",
    "    \n",
    "    def build(self):\n",
    "        self.model=tf.keras.models.load_model(self.model_path)\n",
    "        \n",
    "    def predict_batch(self, model_input, n_products):\n",
    "        scores, products = self.model({k:tf.constant(v) for k,v in model_input.items()})\n",
    "        return products.numpy()[:,:n_products]\n",
    "    \n",
    "    def predict_single(self, model_input, n_products):\n",
    "        scores, products = self.model({k:tf.constant([v]) for k,v in model_input.items()})\n",
    "        return products.numpy()[0,:n_products]\n",
    "    \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5803b4",
   "metadata": {},
   "source": [
    "## stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b27d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "df_grouped = pd.read_csv(TEST_PATH).groupby(ALL_USER_FEATURES)[\"Product_ID\"].apply(list).apply(np.array).reset_index()\n",
    "top_k = [1, 10, 50, 100]\n",
    "results = dict()\n",
    "\n",
    "baseline = BlackFridayBaseline(TRAIN_PATH, ALL_USER_FEATURES, True)\n",
    "for k in tqdm(top_k, leave=False):\n",
    "    metrics_id = f\"baseline_top{k}\"\n",
    "    df_grouped[metrics_id]         = df_grouped[ALL_USER_FEATURES].progress_apply(lambda x: baseline.predict(x, k), axis=1)\n",
    "    baseline_true_positives        = df_grouped.progress_apply(lambda x: np.intersect1d(x[\"Product_ID\"],x[metrics_id]).shape[0], axis=1).sum()\n",
    "    baseline_false_negatives       = df.shape[0] - baseline_true_positives\n",
    "    baseline_false_positives       = df_grouped[metrics_id].apply(lambda x: x.shape[0]).sum() - baseline_true_positives\n",
    "    baseline_reach                 = df_grouped.progress_apply(lambda x: min(x[\"Product_ID\"].shape[0],x[metrics_id].shape[0]), axis=1).sum()\n",
    "    results[f\"baseline_top{k}\"]    = {\n",
    "        \"top\"  : k,\n",
    "        \"model\": \"baseline\",\n",
    "        \"tp\"   : baseline_true_positives,\n",
    "        \"fp\"   : baseline_false_positives,\n",
    "        \"fn\"   : baseline_false_negatives,\n",
    "        \"reach\": baseline_reach #portata\n",
    "    }\n",
    "    \n",
    "\n",
    "metadata_path = os.path.join(\"gs://mlteam-ml-specialization-2021-blackfriday/aiplatform_jobs\", MODEL_NAME, \"metadata.json\")\n",
    "metadata = json.load(tf.io.gfile.GFile(metadata_path, \"r\"))\n",
    "for j in tqdm(metadata, leave=False):\n",
    "    model = PredictionModel(os.path.join(\"gs://mlteam-ml-specialization-2021-blackfriday/aiplatform_jobs\", MODEL_NAME, j['trialId'], 'Scann'), True)\n",
    "    hps = json.dumps(j[\"hyperparameters\"])\n",
    "    model_id = f\"trial_{j['trialId']}\"\n",
    "    for k in tqdm(top_k, leave=False):\n",
    "        metrics_id=f\"trial_{j['trialId']}_top{k}\"\n",
    "        df_grouped[metrics_id] = df_grouped[USER_FEATURES].progress_apply(lambda x: model.predict_single(x.astype(str), k).astype(str), axis=1)\n",
    "        tp = df_grouped.progress_apply(lambda x: np.intersect1d(x[\"Product_ID\"],x[metrics_id]).shape[0], axis=1).sum()\n",
    "        fn = df.shape[0] - tp\n",
    "        fp = df_grouped[metrics_id].apply(lambda x: x.shape[0]).sum() - tp\n",
    "        reach = df_grouped.progress_apply(lambda x: min(len(x[\"Product_ID\"]),x[metrics_id].shape[0]), axis=1).sum() \n",
    "        results[metrics_id] = {\n",
    "            \"top\"  : k,\n",
    "            \"model\": model_id,\n",
    "            \"tp\"   : tp,\n",
    "            \"fp\"   : fp,\n",
    "            \"fn\"   : fn,\n",
    "            \"reach\": reach\n",
    "        }\n",
    "    \n",
    "df_results = pd.DataFrame(results).T\n",
    "df_results[\"precision\"] = df_results[\"tp\"]/(df_results[\"tp\"]+df_results[\"fp\"])\n",
    "df_results[\"recall\"] = df_results[\"tp\"]/(df_results[\"tp\"]+df_results[\"fn\"])\n",
    "df_results[\"tp_over_reach\"] = df_results[\"tp\"]/df_results[\"reach\"]\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb3a761",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.pivot(\"model\",\"top\",\"precision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d09409",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.pivot(\"model\",\"top\",\"recall\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b29388",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.pivot(\"model\",\"top\",\"tp_over_reach\")"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-3.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m65"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
