{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "little-alliance",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tempfile\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_recommenders as tfrs\n",
    "\n",
    "from os.path import join"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exact-latino",
   "metadata": {},
   "source": [
    "## Data load & process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "viral-patio",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train shape:(78366, 12)\n",
      "df_test shape:(156733, 12)\n"
     ]
    }
   ],
   "source": [
    "dataset_parsed_path = \"/home/jupyter/mlspec-blackfriday/dataset/parsed/202104130952/\"\n",
    "train_path = join(dataset_parsed_path, \"train.csv\")\n",
    "test_path = join(dataset_parsed_path, \"eval.csv\")\n",
    "\n",
    "df_train=pd.read_csv(train_path)\n",
    "df_test=pd.read_csv(test_path)\n",
    "\n",
    "# Treat al columns as strings\n",
    "df_train = df_train.astype(str)\n",
    "df_test = df_test.astype(str)\n",
    "\n",
    "print(f\"df_train shape:{df_train.shape}\")\n",
    "print(f\"df_test shape:{df_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "primary-retrieval",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract user info\n",
    "df = df_train.append(df_test)\n",
    "\n",
    "product_features = [\"Product_ID\"]\n",
    "\n",
    "user_features = [\"Gender\", \n",
    "                 \"Age\", \n",
    "                 \"Occupation\", \n",
    "                 \"City_Category\", \n",
    "                 \"Stay_In_Current_City_Years\",\n",
    "                 \"Marital_Status\"\n",
    "                ]\n",
    "\n",
    "product_unique_values = {\n",
    "    feature: df[feature].unique() for feature in product_features\n",
    "}\n",
    "\n",
    "user_unique_values = {\n",
    "    feature: df[feature].unique() for feature in user_features\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "varied-coach",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove columns not used\n",
    "all_features = user_features + product_features\n",
    "\n",
    "df_train = df_train[all_features]\n",
    "df_test = df_test[all_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regulation-celtic",
   "metadata": {},
   "source": [
    "## Model build\n",
    "\n",
    "**Note**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cordless-spending",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserModel(tf.keras.Model):\n",
    "    \"\"\"\n",
    "    Notes:\n",
    "    - Parametric user features\n",
    "    - No closure used\n",
    "    \"\"\"\n",
    "    def __init__(self, unique_values:dict):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.user_features = {}\n",
    "        for feature_name, unique_list in unique_values.items():\n",
    "            feature_layer = tf.keras.Sequential([\n",
    "                                tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "                                    vocabulary=unique_list, mask_token=None),\n",
    "                                    tf.keras.layers.Embedding(len(unique_list) + 1, 32),\n",
    "                            ], feature_name )\n",
    "            self.user_features[feature_name] = feature_layer\n",
    "            \n",
    "\n",
    "\n",
    "    def call(self, inputs):\n",
    "        layers_stack = []\n",
    "        for feature_name, feature_layer in self.user_features.items():\n",
    "            print(f\"Creating layer for feature {feature_name}\")\n",
    "            layer_valorized = feature_layer(inputs[feature_name])\n",
    "            layers_stack.append(layer_valorized)\n",
    "        return tf.concat(layers_stack, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "existing-devon",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProductModel(tf.keras.Model):\n",
    "  \n",
    "    def __init__(self, product_unique_ids:np.ndarray):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.product_embedding = tf.keras.Sequential([\n",
    "          tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "              vocabulary=product_unique_ids, mask_token=None),\n",
    "          tf.keras.layers.Embedding(len(product_unique_ids) + 1, 32)\n",
    "        ])\n",
    "\n",
    "\n",
    "    def call(self, products_id):\n",
    "        return tf.concat([\n",
    "            self.product_embedding(products_id)\n",
    "        ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "rational-breathing",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlackFridayModel(tfrs.models.Model): # note the main package is tfrs\n",
    "    \"\"\"\n",
    "    Note:\n",
    "    - no closure required\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 topk_candidates: tf.data.Dataset,\n",
    "                 user_unique_values: dict,\n",
    "                 product_unique_ids: np.ndarray,\n",
    "                ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.user_features = user_unique_values.keys()\n",
    "        self.query_model = tf.keras.Sequential([\n",
    "                              UserModel(user_unique_values),\n",
    "                              tf.keras.layers.Dense(32)\n",
    "                            ])\n",
    "        self.candidate_model = tf.keras.Sequential([\n",
    "                              ProductModel(product_unique_ids),\n",
    "                              tf.keras.layers.Dense(32)\n",
    "                            ])\n",
    "        # See https://www.tensorflow.org/recommenders/api_docs/python/tfrs/tasks/Retrieval\n",
    "        self.task = tfrs.tasks.Retrieval( # Loss function. Defaults to tf.keras.losses.CategoricalCrossentropy.\n",
    "            metrics=tfrs.metrics.FactorizedTopK( # TODO are we forced to use batch? - REMOVE for training\n",
    "                candidates=topk_candidates.batch(128).map(self.candidate_model), # dataset of candidate embeddings from which candidates should be retrieved (embedded)\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    def compute_loss(self, features, training=False):\n",
    "        query_data = {feature_name: features[feature_name] for feature_name in self.user_features}\n",
    "        query_embeddings = self.query_model(query_data)\n",
    "        product_embeddings = self.candidate_model(features[\"Product_ID\"])\n",
    "        \n",
    "        # Retrieval call: https://www.tensorflow.org/recommenders/api_docs/python/tfrs/tasks/Retrieval\n",
    "        # \"The task will try to maximize the affinity of these query, candidate pairs while minimizing \n",
    "        # the affinity between the query and candidates belonging to other queries in the batch.\"\n",
    "        return self.task(query_embeddings=query_embeddings, \n",
    "                         candidate_embeddings=product_embeddings,\n",
    "                         compute_metrics=True, # disable for better performances\n",
    "                         candidate_ids = None\n",
    "                        )\n",
    "    def call(self, features):\n",
    "        query_data = {feature_name: features[feature_name] for feature_name in self.user_features}\n",
    "        query_embeddings = self.query_model(query_data)\n",
    "        self.task = tfrs.tasks.Retrieval( # Loss function. Defaults to tf.keras.losses.CategoricalCrossentropy.\n",
    "            metrics=tfrs.metrics.FactorizedTopK( # TODO are we forced to use batch? - REMOVE for training\n",
    "                candidates=topk_candidates.batch(128).map(self.candidate_model), # dataset of candidate embeddings from which candidates should be retrieved (embedded)\n",
    "            ),\n",
    "        )\n",
    "        return query_data, query_embeddings, self.task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "turkish-builder",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "utility-martial",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorSpec(shape=(), dtype=tf.string, name=None)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Candidates to use for metrics\n",
    "tf_unique_products = tf.data.Dataset.from_tensor_slices(product_unique_values[\"Product_ID\"])\n",
    "tf_unique_products.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "outstanding-defensive",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BlackFridayModel(\n",
    "                        topk_candidates = tf_unique_products,\n",
    "                        user_unique_values = user_unique_values,\n",
    "                        product_unique_ids = product_unique_values[\"Product_ID\"]\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fleet-array",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tf dataset\n",
    "tf.random.set_seed(42)\n",
    "train = tf.data.Dataset.from_tensor_slices(dict(df_train)) # dict is important\n",
    "train = train.shuffle(100_000, seed=42, reshuffle_each_iteration=False)\n",
    "\n",
    "test = tf.data.Dataset.from_tensor_slices(dict(df_test))\n",
    "\n",
    "cached_train = train.shuffle(100_000).batch(2048) # TODO: double shuffle?\n",
    "cached_test = test.batch(4096).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "minor-channels",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'Gender': TensorSpec(shape=(None,), dtype=tf.string, name=None),\n",
       "  'Age': TensorSpec(shape=(None,), dtype=tf.string, name=None),\n",
       "  'Occupation': TensorSpec(shape=(None,), dtype=tf.string, name=None),\n",
       "  'City_Category': TensorSpec(shape=(None,), dtype=tf.string, name=None),\n",
       "  'Stay_In_Current_City_Years': TensorSpec(shape=(None,), dtype=tf.string, name=None),\n",
       "  'Marital_Status': TensorSpec(shape=(None,), dtype=tf.string, name=None),\n",
       "  'Product_ID': TensorSpec(shape=(None,), dtype=tf.string, name=None)},\n",
       " {'Gender': TensorSpec(shape=(None,), dtype=tf.string, name=None),\n",
       "  'Age': TensorSpec(shape=(None,), dtype=tf.string, name=None),\n",
       "  'Occupation': TensorSpec(shape=(None,), dtype=tf.string, name=None),\n",
       "  'City_Category': TensorSpec(shape=(None,), dtype=tf.string, name=None),\n",
       "  'Stay_In_Current_City_Years': TensorSpec(shape=(None,), dtype=tf.string, name=None),\n",
       "  'Marital_Status': TensorSpec(shape=(None,), dtype=tf.string, name=None),\n",
       "  'Product_ID': TensorSpec(shape=(None,), dtype=tf.string, name=None)})"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cached_train.element_spec, cached_test.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "biblical-brake",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a callback that saves the model's weights\n",
    "from datetime import datetime\n",
    "run_id = datetime.today().strftime('%Y%m%d%H%M%S')\n",
    "\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=f\"./models/{run_id}/\",\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "preceding-leonard",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'Gender': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'Age': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'Occupation': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=string>, 'City_Category': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'Stay_In_Current_City_Years': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=string>, 'Marital_Status': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=string>}\n",
      "Consider rewriting this model with the Functional API.\n",
      "Creating layer for feature Gender\n",
      "Creating layer for feature Age\n",
      "Creating layer for feature Occupation\n",
      "Creating layer for feature City_Category\n",
      "Creating layer for feature Stay_In_Current_City_Years\n",
      "Creating layer for feature Marital_Status\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'Gender': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'Age': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'Occupation': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=string>, 'City_Category': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'Stay_In_Current_City_Years': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=string>, 'Marital_Status': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=string>}\n",
      "Consider rewriting this model with the Functional API.\n",
      "Creating layer for feature Gender\n",
      "Creating layer for feature Age\n",
      "Creating layer for feature Occupation\n",
      "Creating layer for feature City_Category\n",
      "Creating layer for feature Stay_In_Current_City_Years\n",
      "Creating layer for feature Marital_Status\n",
      "39/39 [==============================] - 36s 889ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0026 - factorized_top_k/top_5_categorical_accuracy: 0.0067 - factorized_top_k/top_10_categorical_accuracy: 0.0108 - factorized_top_k/top_50_categorical_accuracy: 0.0352 - factorized_top_k/top_100_categorical_accuracy: 0.0615 - loss: 15061.6912 - regularization_loss: 0.0000e+00 - total_loss: 15061.6912\n",
      "\n",
      "Epoch 00001: saving model to ./\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f5c896f3890>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))\n",
    "model.fit(cached_train, epochs=1, callbacks=cp_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "consecutive-hundred",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 62s 2s/step - factorized_top_k/top_1_categorical_accuracy: 5.1680e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0032 - factorized_top_k/top_10_categorical_accuracy: 0.0060 - factorized_top_k/top_50_categorical_accuracy: 0.0289 - factorized_top_k/top_100_categorical_accuracy: 0.0571 - loss: 32594.5969 - regularization_loss: 0.0000e+00 - total_loss: 32594.5969\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = model.evaluate(\n",
    "    cached_test, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "durable-princess",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'Gender': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'Age': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'Occupation': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=string>, 'City_Category': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'Stay_In_Current_City_Years': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=string>, 'Marital_Status': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=string>}\n",
      "Consider rewriting this model with the Functional API.\n",
      "Creating layer for feature Gender\n",
      "Creating layer for feature Age\n",
      "Creating layer for feature Occupation\n",
      "Creating layer for feature City_Category\n",
      "Creating layer for feature Stay_In_Current_City_Years\n",
      "Creating layer for feature Marital_Status\n",
      "39/39 [==============================] - 32s 799ms/step - factorized_top_k/top_1_categorical_accuracy: 8.8048e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0055 - factorized_top_k/top_10_categorical_accuracy: 0.0105 - factorized_top_k/top_50_categorical_accuracy: 0.0437 - factorized_top_k/top_100_categorical_accuracy: 0.0822 - loss: 14821.8111 - regularization_loss: 0.0000e+00 - total_loss: 14821.8111\n",
      "39/39 [==============================] - 62s 2s/step - factorized_top_k/top_1_categorical_accuracy: 5.1680e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0032 - factorized_top_k/top_10_categorical_accuracy: 0.0060 - factorized_top_k/top_50_categorical_accuracy: 0.0289 - factorized_top_k/top_100_categorical_accuracy: 0.0571 - loss: 32594.5969 - regularization_loss: 0.0000e+00 - total_loss: 32594.5969\n",
      "Top-100 accuracy (train): 0.08.\n",
      "Top-100 accuracy (test): 0.06.\n"
     ]
    }
   ],
   "source": [
    "train_accuracy = model.evaluate(\n",
    "    cached_train, return_dict=True)[\"factorized_top_k/top_100_categorical_accuracy\"]\n",
    "test_accuracy = model.evaluate(\n",
    "    cached_test, return_dict=True)[\"factorized_top_k/top_100_categorical_accuracy\"]\n",
    "    \n",
    "print(f\"Top-100 accuracy (train): {train_accuracy:.2f}.\")\n",
    "print(f\"Top-100 accuracy (test): {test_accuracy:.2f}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "illegal-arena",
   "metadata": {},
   "source": [
    "---\n",
    "## Train more epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "checked-punch",
   "metadata": {},
   "source": [
    "### 10 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "funded-craps",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'User_ID': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=string>, 'Gender': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'Age': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'Occupation': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=string>, 'City_Category': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'Stay_In_Current_City_Years': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=string>, 'Marital_Status': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=string>}\n",
      "Consider rewriting this model with the Functional API.\n",
      "Creating layer for feature User_ID\n",
      "Creating layer for feature Gender\n",
      "Creating layer for feature Age\n",
      "Creating layer for feature Occupation\n",
      "Creating layer for feature City_Category\n",
      "Creating layer for feature Stay_In_Current_City_Years\n",
      "Creating layer for feature Marital_Status\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'User_ID': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=string>, 'Gender': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'Age': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'Occupation': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=string>, 'City_Category': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'Stay_In_Current_City_Years': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=string>, 'Marital_Status': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=string>}\n",
      "Consider rewriting this model with the Functional API.\n",
      "Creating layer for feature User_ID\n",
      "Creating layer for feature Gender\n",
      "Creating layer for feature Age\n",
      "Creating layer for feature Occupation\n",
      "Creating layer for feature City_Category\n",
      "Creating layer for feature Stay_In_Current_City_Years\n",
      "Creating layer for feature Marital_Status\n",
      "39/39 [==============================] - 12s 274ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0052 - factorized_top_k/top_5_categorical_accuracy: 0.0281 - factorized_top_k/top_10_categorical_accuracy: 0.0454 - factorized_top_k/top_50_categorical_accuracy: 0.1334 - factorized_top_k/top_100_categorical_accuracy: 0.2030 - loss: 14070.9312 - regularization_loss: 0.0000e+00 - total_loss: 14070.9312\n",
      "Epoch 2/10\n",
      "39/39 [==============================] - 12s 288ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0022 - factorized_top_k/top_5_categorical_accuracy: 0.0507 - factorized_top_k/top_10_categorical_accuracy: 0.0829 - factorized_top_k/top_50_categorical_accuracy: 0.2149 - factorized_top_k/top_100_categorical_accuracy: 0.3079 - loss: 13062.9445 - regularization_loss: 0.0000e+00 - total_loss: 13062.9445\n",
      "Epoch 3/10\n",
      "39/39 [==============================] - 12s 292ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0036 - factorized_top_k/top_5_categorical_accuracy: 0.0710 - factorized_top_k/top_10_categorical_accuracy: 0.1123 - factorized_top_k/top_50_categorical_accuracy: 0.2647 - factorized_top_k/top_100_categorical_accuracy: 0.3642 - loss: 12588.0838 - regularization_loss: 0.0000e+00 - total_loss: 12588.0838\n",
      "Epoch 4/10\n",
      "39/39 [==============================] - 11s 278ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0057 - factorized_top_k/top_5_categorical_accuracy: 0.0852 - factorized_top_k/top_10_categorical_accuracy: 0.1338 - factorized_top_k/top_50_categorical_accuracy: 0.3039 - factorized_top_k/top_100_categorical_accuracy: 0.4063 - loss: 12262.3149 - regularization_loss: 0.0000e+00 - total_loss: 12262.3149\n",
      "Epoch 5/10\n",
      "39/39 [==============================] - 11s 275ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0068 - factorized_top_k/top_5_categorical_accuracy: 0.0958 - factorized_top_k/top_10_categorical_accuracy: 0.1516 - factorized_top_k/top_50_categorical_accuracy: 0.3341 - factorized_top_k/top_100_categorical_accuracy: 0.4388 - loss: 12021.8109 - regularization_loss: 0.0000e+00 - total_loss: 12021.8109\n",
      "Epoch 6/10\n",
      "39/39 [==============================] - 11s 270ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0081 - factorized_top_k/top_5_categorical_accuracy: 0.1073 - factorized_top_k/top_10_categorical_accuracy: 0.1668 - factorized_top_k/top_50_categorical_accuracy: 0.3573 - factorized_top_k/top_100_categorical_accuracy: 0.4654 - loss: 11831.5604 - regularization_loss: 0.0000e+00 - total_loss: 11831.5604\n",
      "Epoch 7/10\n",
      "39/39 [==============================] - 11s 270ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0090 - factorized_top_k/top_5_categorical_accuracy: 0.1139 - factorized_top_k/top_10_categorical_accuracy: 0.1779 - factorized_top_k/top_50_categorical_accuracy: 0.3766 - factorized_top_k/top_100_categorical_accuracy: 0.4847 - loss: 11684.6867 - regularization_loss: 0.0000e+00 - total_loss: 11684.6867\n",
      "Epoch 8/10\n",
      "39/39 [==============================] - 11s 272ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0100 - factorized_top_k/top_5_categorical_accuracy: 0.1208 - factorized_top_k/top_10_categorical_accuracy: 0.1884 - factorized_top_k/top_50_categorical_accuracy: 0.3917 - factorized_top_k/top_100_categorical_accuracy: 0.5019 - loss: 11559.7199 - regularization_loss: 0.0000e+00 - total_loss: 11559.7199\n",
      "Epoch 9/10\n",
      "39/39 [==============================] - 11s 275ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0097 - factorized_top_k/top_5_categorical_accuracy: 0.1268 - factorized_top_k/top_10_categorical_accuracy: 0.1976 - factorized_top_k/top_50_categorical_accuracy: 0.4045 - factorized_top_k/top_100_categorical_accuracy: 0.5152 - loss: 11452.3655 - regularization_loss: 0.0000e+00 - total_loss: 11452.3655\n",
      "Epoch 10/10\n",
      "39/39 [==============================] - 11s 274ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0111 - factorized_top_k/top_5_categorical_accuracy: 0.1327 - factorized_top_k/top_10_categorical_accuracy: 0.2056 - factorized_top_k/top_50_categorical_accuracy: 0.4179 - factorized_top_k/top_100_categorical_accuracy: 0.5280 - loss: 11362.6860 - regularization_loss: 0.0000e+00 - total_loss: 11362.6860\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'User_ID': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=string>, 'Gender': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'Age': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'Occupation': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=string>, 'City_Category': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'Stay_In_Current_City_Years': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=string>, 'Marital_Status': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=string>}\n",
      "Consider rewriting this model with the Functional API.\n",
      "Creating layer for feature User_ID\n",
      "Creating layer for feature Gender\n",
      "Creating layer for feature Age\n",
      "Creating layer for feature Occupation\n",
      "Creating layer for feature City_Category\n",
      "Creating layer for feature Stay_In_Current_City_Years\n",
      "Creating layer for feature Marital_Status\n",
      "39/39 [==============================] - 11s 269ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0421 - factorized_top_k/top_5_categorical_accuracy: 0.1774 - factorized_top_k/top_10_categorical_accuracy: 0.2516 - factorized_top_k/top_50_categorical_accuracy: 0.4603 - factorized_top_k/top_100_categorical_accuracy: 0.5687 - loss: 10875.6500 - regularization_loss: 0.0000e+00 - total_loss: 10875.6500\n",
      "39/39 [==============================] - 18s 455ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0023 - factorized_top_k/top_5_categorical_accuracy: 0.0109 - factorized_top_k/top_10_categorical_accuracy: 0.0179 - factorized_top_k/top_50_categorical_accuracy: 0.0577 - factorized_top_k/top_100_categorical_accuracy: 0.0995 - loss: 37376.7665 - regularization_loss: 0.0000e+00 - total_loss: 37376.7665\n",
      "Top-100 accuracy (train): 0.57.\n",
      "Top-100 accuracy (test): 0.10.\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))\n",
    "model.fit(cached_train, epochs=10)\n",
    "train_accuracy = model.evaluate(\n",
    "    cached_train, return_dict=True)[\"factorized_top_k/top_100_categorical_accuracy\"]\n",
    "test_accuracy = model.evaluate(\n",
    "    cached_test, return_dict=True)[\"factorized_top_k/top_100_categorical_accuracy\"]\n",
    "    \n",
    "print(f\"Top-100 accuracy (train): {train_accuracy:.2f}.\")\n",
    "print(f\"Top-100 accuracy (test): {test_accuracy:.2f}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorporated-exposure",
   "metadata": {},
   "source": [
    "### 30 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "graphic-party",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'User_ID': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=string>, 'Gender': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'Age': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'Occupation': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=string>, 'City_Category': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'Stay_In_Current_City_Years': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=string>, 'Marital_Status': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=string>}\n",
      "Consider rewriting this model with the Functional API.\n",
      "Creating layer for feature User_ID\n",
      "Creating layer for feature Gender\n",
      "Creating layer for feature Age\n",
      "Creating layer for feature Occupation\n",
      "Creating layer for feature City_Category\n",
      "Creating layer for feature Stay_In_Current_City_Years\n",
      "Creating layer for feature Marital_Status\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'User_ID': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=string>, 'Gender': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'Age': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'Occupation': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=string>, 'City_Category': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'Stay_In_Current_City_Years': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=string>, 'Marital_Status': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=string>}\n",
      "Consider rewriting this model with the Functional API.\n",
      "Creating layer for feature User_ID\n",
      "Creating layer for feature Gender\n",
      "Creating layer for feature Age\n",
      "Creating layer for feature Occupation\n",
      "Creating layer for feature City_Category\n",
      "Creating layer for feature Stay_In_Current_City_Years\n",
      "Creating layer for feature Marital_Status\n",
      "39/39 [==============================] - 12s 278ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0074 - factorized_top_k/top_5_categorical_accuracy: 0.0618 - factorized_top_k/top_10_categorical_accuracy: 0.0991 - factorized_top_k/top_50_categorical_accuracy: 0.2513 - factorized_top_k/top_100_categorical_accuracy: 0.3535 - loss: 13026.4022 - regularization_loss: 0.0000e+00 - total_loss: 13026.4022\n",
      "Epoch 2/30\n",
      "39/39 [==============================] - 11s 274ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0096 - factorized_top_k/top_5_categorical_accuracy: 0.1046 - factorized_top_k/top_10_categorical_accuracy: 0.1677 - factorized_top_k/top_50_categorical_accuracy: 0.3632 - factorized_top_k/top_100_categorical_accuracy: 0.4739 - loss: 11797.6142 - regularization_loss: 0.0000e+00 - total_loss: 11797.6142\n",
      "Epoch 3/30\n",
      "39/39 [==============================] - 11s 273ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0103 - factorized_top_k/top_5_categorical_accuracy: 0.1242 - factorized_top_k/top_10_categorical_accuracy: 0.1968 - factorized_top_k/top_50_categorical_accuracy: 0.4052 - factorized_top_k/top_100_categorical_accuracy: 0.5131 - loss: 11486.1954 - regularization_loss: 0.0000e+00 - total_loss: 11486.1954\n",
      "Epoch 4/30\n",
      "39/39 [==============================] - 11s 271ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0106 - factorized_top_k/top_5_categorical_accuracy: 0.1378 - factorized_top_k/top_10_categorical_accuracy: 0.2143 - factorized_top_k/top_50_categorical_accuracy: 0.4289 - factorized_top_k/top_100_categorical_accuracy: 0.5387 - loss: 11285.3512 - regularization_loss: 0.0000e+00 - total_loss: 11285.3512\n",
      "Epoch 5/30\n",
      "39/39 [==============================] - 11s 272ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0113 - factorized_top_k/top_5_categorical_accuracy: 0.1455 - factorized_top_k/top_10_categorical_accuracy: 0.2275 - factorized_top_k/top_50_categorical_accuracy: 0.4454 - factorized_top_k/top_100_categorical_accuracy: 0.5557 - loss: 11144.5754 - regularization_loss: 0.0000e+00 - total_loss: 11144.5754\n",
      "Epoch 6/30\n",
      "39/39 [==============================] - 11s 269ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0119 - factorized_top_k/top_5_categorical_accuracy: 0.1508 - factorized_top_k/top_10_categorical_accuracy: 0.2358 - factorized_top_k/top_50_categorical_accuracy: 0.4589 - factorized_top_k/top_100_categorical_accuracy: 0.5676 - loss: 11032.3342 - regularization_loss: 0.0000e+00 - total_loss: 11032.3342\n",
      "Epoch 7/30\n",
      "39/39 [==============================] - 11s 274ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0123 - factorized_top_k/top_5_categorical_accuracy: 0.1566 - factorized_top_k/top_10_categorical_accuracy: 0.2451 - factorized_top_k/top_50_categorical_accuracy: 0.4704 - factorized_top_k/top_100_categorical_accuracy: 0.5792 - loss: 10937.1203 - regularization_loss: 0.0000e+00 - total_loss: 10937.1203\n",
      "Epoch 8/30\n",
      "39/39 [==============================] - 11s 272ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0120 - factorized_top_k/top_5_categorical_accuracy: 0.1615 - factorized_top_k/top_10_categorical_accuracy: 0.2506 - factorized_top_k/top_50_categorical_accuracy: 0.4774 - factorized_top_k/top_100_categorical_accuracy: 0.5881 - loss: 10855.5641 - regularization_loss: 0.0000e+00 - total_loss: 10855.5641\n",
      "Epoch 9/30\n",
      "39/39 [==============================] - 11s 273ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0117 - factorized_top_k/top_5_categorical_accuracy: 0.1640 - factorized_top_k/top_10_categorical_accuracy: 0.2576 - factorized_top_k/top_50_categorical_accuracy: 0.4867 - factorized_top_k/top_100_categorical_accuracy: 0.5947 - loss: 10788.0378 - regularization_loss: 0.0000e+00 - total_loss: 10788.0378\n",
      "Epoch 10/30\n",
      "39/39 [==============================] - 11s 274ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0120 - factorized_top_k/top_5_categorical_accuracy: 0.1684 - factorized_top_k/top_10_categorical_accuracy: 0.2626 - factorized_top_k/top_50_categorical_accuracy: 0.4930 - factorized_top_k/top_100_categorical_accuracy: 0.6015 - loss: 10724.6230 - regularization_loss: 0.0000e+00 - total_loss: 10724.6230\n",
      "Epoch 11/30\n",
      "39/39 [==============================] - 11s 284ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0126 - factorized_top_k/top_5_categorical_accuracy: 0.1713 - factorized_top_k/top_10_categorical_accuracy: 0.2669 - factorized_top_k/top_50_categorical_accuracy: 0.5002 - factorized_top_k/top_100_categorical_accuracy: 0.6082 - loss: 10665.0961 - regularization_loss: 0.0000e+00 - total_loss: 10665.0961\n",
      "Epoch 12/30\n",
      "39/39 [==============================] - 11s 274ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0125 - factorized_top_k/top_5_categorical_accuracy: 0.1741 - factorized_top_k/top_10_categorical_accuracy: 0.2717 - factorized_top_k/top_50_categorical_accuracy: 0.5057 - factorized_top_k/top_100_categorical_accuracy: 0.6141 - loss: 10614.4632 - regularization_loss: 0.0000e+00 - total_loss: 10614.4632\n",
      "Epoch 13/30\n",
      "39/39 [==============================] - 11s 275ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0129 - factorized_top_k/top_5_categorical_accuracy: 0.1770 - factorized_top_k/top_10_categorical_accuracy: 0.2759 - factorized_top_k/top_50_categorical_accuracy: 0.5121 - factorized_top_k/top_100_categorical_accuracy: 0.6188 - loss: 10569.4929 - regularization_loss: 0.0000e+00 - total_loss: 10569.4929\n",
      "Epoch 14/30\n",
      "39/39 [==============================] - 11s 273ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0130 - factorized_top_k/top_5_categorical_accuracy: 0.1791 - factorized_top_k/top_10_categorical_accuracy: 0.2807 - factorized_top_k/top_50_categorical_accuracy: 0.5174 - factorized_top_k/top_100_categorical_accuracy: 0.6236 - loss: 10528.8487 - regularization_loss: 0.0000e+00 - total_loss: 10528.8487\n",
      "Epoch 15/30\n",
      "39/39 [==============================] - 11s 274ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0128 - factorized_top_k/top_5_categorical_accuracy: 0.1809 - factorized_top_k/top_10_categorical_accuracy: 0.2834 - factorized_top_k/top_50_categorical_accuracy: 0.5228 - factorized_top_k/top_100_categorical_accuracy: 0.6272 - loss: 10488.9813 - regularization_loss: 0.0000e+00 - total_loss: 10488.9813\n",
      "Epoch 16/30\n",
      "39/39 [==============================] - 11s 272ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0124 - factorized_top_k/top_5_categorical_accuracy: 0.1834 - factorized_top_k/top_10_categorical_accuracy: 0.2875 - factorized_top_k/top_50_categorical_accuracy: 0.5259 - factorized_top_k/top_100_categorical_accuracy: 0.6318 - loss: 10449.1952 - regularization_loss: 0.0000e+00 - total_loss: 10449.1952\n",
      "Epoch 17/30\n",
      "39/39 [==============================] - 11s 272ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0129 - factorized_top_k/top_5_categorical_accuracy: 0.1846 - factorized_top_k/top_10_categorical_accuracy: 0.2910 - factorized_top_k/top_50_categorical_accuracy: 0.5293 - factorized_top_k/top_100_categorical_accuracy: 0.6353 - loss: 10414.1063 - regularization_loss: 0.0000e+00 - total_loss: 10414.1063\n",
      "Epoch 18/30\n",
      "39/39 [==============================] - 11s 270ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0132 - factorized_top_k/top_5_categorical_accuracy: 0.1859 - factorized_top_k/top_10_categorical_accuracy: 0.2943 - factorized_top_k/top_50_categorical_accuracy: 0.5329 - factorized_top_k/top_100_categorical_accuracy: 0.6380 - loss: 10385.7644 - regularization_loss: 0.0000e+00 - total_loss: 10385.7644\n",
      "Epoch 19/30\n",
      "39/39 [==============================] - 11s 270ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0138 - factorized_top_k/top_5_categorical_accuracy: 0.1878 - factorized_top_k/top_10_categorical_accuracy: 0.2972 - factorized_top_k/top_50_categorical_accuracy: 0.5376 - factorized_top_k/top_100_categorical_accuracy: 0.6432 - loss: 10352.5852 - regularization_loss: 0.0000e+00 - total_loss: 10352.5852\n",
      "Epoch 20/30\n",
      "39/39 [==============================] - 11s 272ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0128 - factorized_top_k/top_5_categorical_accuracy: 0.1899 - factorized_top_k/top_10_categorical_accuracy: 0.2990 - factorized_top_k/top_50_categorical_accuracy: 0.5412 - factorized_top_k/top_100_categorical_accuracy: 0.6441 - loss: 10320.4427 - regularization_loss: 0.0000e+00 - total_loss: 10320.4427\n",
      "Epoch 21/30\n",
      "39/39 [==============================] - 11s 270ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0136 - factorized_top_k/top_5_categorical_accuracy: 0.1911 - factorized_top_k/top_10_categorical_accuracy: 0.3017 - factorized_top_k/top_50_categorical_accuracy: 0.5435 - factorized_top_k/top_100_categorical_accuracy: 0.6476 - loss: 10297.9576 - regularization_loss: 0.0000e+00 - total_loss: 10297.9576\n",
      "Epoch 22/30\n",
      "39/39 [==============================] - 11s 271ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0134 - factorized_top_k/top_5_categorical_accuracy: 0.1918 - factorized_top_k/top_10_categorical_accuracy: 0.3035 - factorized_top_k/top_50_categorical_accuracy: 0.5464 - factorized_top_k/top_100_categorical_accuracy: 0.6507 - loss: 10270.4640 - regularization_loss: 0.0000e+00 - total_loss: 10270.4640\n",
      "Epoch 23/30\n",
      "39/39 [==============================] - 11s 273ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0136 - factorized_top_k/top_5_categorical_accuracy: 0.1924 - factorized_top_k/top_10_categorical_accuracy: 0.3071 - factorized_top_k/top_50_categorical_accuracy: 0.5492 - factorized_top_k/top_100_categorical_accuracy: 0.6527 - loss: 10245.9877 - regularization_loss: 0.0000e+00 - total_loss: 10245.9877\n",
      "Epoch 24/30\n",
      "39/39 [==============================] - 11s 274ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0138 - factorized_top_k/top_5_categorical_accuracy: 0.1949 - factorized_top_k/top_10_categorical_accuracy: 0.3091 - factorized_top_k/top_50_categorical_accuracy: 0.5519 - factorized_top_k/top_100_categorical_accuracy: 0.6557 - loss: 10224.2620 - regularization_loss: 0.0000e+00 - total_loss: 10224.2620\n",
      "Epoch 25/30\n",
      "39/39 [==============================] - 11s 273ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0139 - factorized_top_k/top_5_categorical_accuracy: 0.1958 - factorized_top_k/top_10_categorical_accuracy: 0.3104 - factorized_top_k/top_50_categorical_accuracy: 0.5542 - factorized_top_k/top_100_categorical_accuracy: 0.6580 - loss: 10202.6307 - regularization_loss: 0.0000e+00 - total_loss: 10202.6307\n",
      "Epoch 26/30\n",
      "39/39 [==============================] - 11s 273ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0136 - factorized_top_k/top_5_categorical_accuracy: 0.1974 - factorized_top_k/top_10_categorical_accuracy: 0.3118 - factorized_top_k/top_50_categorical_accuracy: 0.5571 - factorized_top_k/top_100_categorical_accuracy: 0.6598 - loss: 10180.0004 - regularization_loss: 0.0000e+00 - total_loss: 10180.0004\n",
      "Epoch 27/30\n",
      "39/39 [==============================] - 11s 274ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0134 - factorized_top_k/top_5_categorical_accuracy: 0.1990 - factorized_top_k/top_10_categorical_accuracy: 0.3150 - factorized_top_k/top_50_categorical_accuracy: 0.5595 - factorized_top_k/top_100_categorical_accuracy: 0.6625 - loss: 10158.3343 - regularization_loss: 0.0000e+00 - total_loss: 10158.3343\n",
      "Epoch 28/30\n",
      "39/39 [==============================] - 11s 271ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0141 - factorized_top_k/top_5_categorical_accuracy: 0.2002 - factorized_top_k/top_10_categorical_accuracy: 0.3162 - factorized_top_k/top_50_categorical_accuracy: 0.5616 - factorized_top_k/top_100_categorical_accuracy: 0.6641 - loss: 10139.9226 - regularization_loss: 0.0000e+00 - total_loss: 10139.9226\n",
      "Epoch 29/30\n",
      "39/39 [==============================] - 11s 270ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0140 - factorized_top_k/top_5_categorical_accuracy: 0.2006 - factorized_top_k/top_10_categorical_accuracy: 0.3180 - factorized_top_k/top_50_categorical_accuracy: 0.5626 - factorized_top_k/top_100_categorical_accuracy: 0.6655 - loss: 10125.7557 - regularization_loss: 0.0000e+00 - total_loss: 10125.7557\n",
      "Epoch 30/30\n",
      "39/39 [==============================] - 11s 272ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0138 - factorized_top_k/top_5_categorical_accuracy: 0.2016 - factorized_top_k/top_10_categorical_accuracy: 0.3194 - factorized_top_k/top_50_categorical_accuracy: 0.5648 - factorized_top_k/top_100_categorical_accuracy: 0.6678 - loss: 10103.3817 - regularization_loss: 0.0000e+00 - total_loss: 10103.3817\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'User_ID': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=string>, 'Gender': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'Age': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'Occupation': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=string>, 'City_Category': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'Stay_In_Current_City_Years': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=string>, 'Marital_Status': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=string>}\n",
      "Consider rewriting this model with the Functional API.\n",
      "Creating layer for feature User_ID\n",
      "Creating layer for feature Gender\n",
      "Creating layer for feature Age\n",
      "Creating layer for feature Occupation\n",
      "Creating layer for feature City_Category\n",
      "Creating layer for feature Stay_In_Current_City_Years\n",
      "Creating layer for feature Marital_Status\n",
      "39/39 [==============================] - 11s 271ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0506 - factorized_top_k/top_5_categorical_accuracy: 0.2539 - factorized_top_k/top_10_categorical_accuracy: 0.3629 - factorized_top_k/top_50_categorical_accuracy: 0.5907 - factorized_top_k/top_100_categorical_accuracy: 0.6891 - loss: 9780.5670 - regularization_loss: 0.0000e+00 - total_loss: 9780.5670\n",
      "39/39 [==============================] - 18s 451ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0027 - factorized_top_k/top_5_categorical_accuracy: 0.0151 - factorized_top_k/top_10_categorical_accuracy: 0.0241 - factorized_top_k/top_50_categorical_accuracy: 0.0721 - factorized_top_k/top_100_categorical_accuracy: 0.1220 - loss: 43466.2716 - regularization_loss: 0.0000e+00 - total_loss: 43466.2716\n",
      "Top-100 accuracy (train): 0.69.\n",
      "Top-100 accuracy (test): 0.12.\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))\n",
    "model.fit(cached_train, epochs=30)\n",
    "train_accuracy = model.evaluate(\n",
    "    cached_train, return_dict=True)[\"factorized_top_k/top_100_categorical_accuracy\"]\n",
    "test_accuracy = model.evaluate(\n",
    "    cached_test, return_dict=True)[\"factorized_top_k/top_100_categorical_accuracy\"]\n",
    "    \n",
    "print(f\"Top-100 accuracy (train): {train_accuracy:.2f}.\")\n",
    "print(f\"Top-100 accuracy (test): {test_accuracy:.2f}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dressed-bathroom",
   "metadata": {},
   "source": [
    "---\n",
    "- check pip install netron"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-3.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m65"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
