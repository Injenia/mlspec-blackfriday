{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9de35d38",
   "metadata": {},
   "source": [
    "# Retrieval stage\n",
    "> \"The retrieval stage is responsible for selecting an initial set of hundreds of candidates from all possible candidates. The main objective of this model is to efficiently weed out all candidates that the user is not interested in. Because the retrieval model may be dealing with millions of candidates, it has to be computationally efficient. - [tf](https://github.com/tensorflow/recommenders/blob/main/docs/examples/basic_retrieval.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa9ba5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tempfile\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_recommenders as tfrs\n",
    "\n",
    "from os.path import join"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bccc876",
   "metadata": {},
   "source": [
    "## Data load & process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edc80fa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train shape:(78366, 12)\n",
      "df_test shape:(156733, 12)\n"
     ]
    }
   ],
   "source": [
    "dataset_parsed_path = \"/home/jupyter/mlspec-blackfriday/dataset/parsed/202104130952/\"\n",
    "train_path = join(dataset_parsed_path, \"train.csv\")\n",
    "test_path = join(dataset_parsed_path, \"eval.csv\")\n",
    "\n",
    "df_train=pd.read_csv(train_path)\n",
    "df_test=pd.read_csv(test_path)\n",
    "\n",
    "# Treat al columns as strings\n",
    "df_train = df_train.astype(str)\n",
    "df_test = df_test.astype(str)\n",
    "\n",
    "print(f\"df_train shape:{df_train.shape}\")\n",
    "print(f\"df_test shape:{df_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17e1e4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define used features\n",
    "\n",
    "product_features = [\"Product_ID\"]\n",
    "\n",
    "user_features = [\"Gender\", \n",
    "                 \"Age\", \n",
    "                 \"Occupation\", \n",
    "                 \"City_Category\", \n",
    "                 \"Stay_In_Current_City_Years\",\n",
    "                 \"Marital_Status\"\n",
    "                ]\n",
    "\n",
    "# Remove columns not used\n",
    "all_features = user_features + product_features\n",
    "\n",
    "df_train = df_train[all_features]\n",
    "df_test = df_test[all_features]\n",
    "\n",
    "# Extract unique info\n",
    "df = df_train.append(df_test)\n",
    "\n",
    "product_unique_values = {\n",
    "    feature: df[feature].unique() for feature in product_features\n",
    "}\n",
    "\n",
    "user_unique_values = {\n",
    "    feature: df[feature].unique() for feature in user_features\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa113cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>City_Category</th>\n",
       "      <th>Stay_In_Current_City_Years</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Product_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>26-35</td>\n",
       "      <td>14</td>\n",
       "      <td>B</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>P00235842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>26-35</td>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>P00180442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>36-45</td>\n",
       "      <td>2</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>P00303842</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Gender    Age Occupation City_Category Stay_In_Current_City_Years  \\\n",
       "0      M  26-35         14             B                          2   \n",
       "1      M  26-35          0             C                          1   \n",
       "2      M  36-45          2             A                          2   \n",
       "\n",
       "  Marital_Status Product_ID  \n",
       "0              1  P00235842  \n",
       "1              0  P00180442  \n",
       "2              0  P00303842  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Training set:\")\n",
    "df_train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960f5e31",
   "metadata": {},
   "source": [
    "## Model build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ee164db",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserModel(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, unique_values:dict): # [Gender, [M, F]]\n",
    "        super().__init__()\n",
    "        \n",
    "        self.user_features = {}\n",
    "        for feature_name, unique_list in unique_values.items():\n",
    "            feature_layer = tf.keras.Sequential([\n",
    "                                tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "                                    vocabulary=unique_list, mask_token=None),\n",
    "                                    tf.keras.layers.Embedding(len(unique_list) + 1, 32),\n",
    "                            ], feature_name )\n",
    "            self.user_features[feature_name] = feature_layer\n",
    "            \n",
    "\n",
    "\n",
    "    def call(self, inputs):\n",
    "        layers_stack = []\n",
    "        for feature_name, feature_layer in self.user_features.items():\n",
    "            print(f\"Creating layer for feature {feature_name}\")\n",
    "            layer_valorized = feature_layer(inputs[feature_name])\n",
    "            layers_stack.append(layer_valorized)\n",
    "        return tf.concat(layers_stack, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "977b23a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProductModel(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self, product_unique_ids:np.ndarray):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.product_embedding = tf.keras.Sequential([\n",
    "          tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "              vocabulary=product_unique_ids, mask_token=None),\n",
    "          tf.keras.layers.Embedding(len(product_unique_ids) + 1, 32)\n",
    "        ])\n",
    "\n",
    "\n",
    "    def call(self, products_id):\n",
    "        return tf.concat([\n",
    "            self.product_embedding(products_id)\n",
    "        ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6f66519",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlackFridayModel(tfrs.models.Model): # note the main package is tfrs\n",
    "    \"\"\"\n",
    "    Note:\n",
    "    - no closure required\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 user_model,\n",
    "                 product_model,\n",
    "                 topk_candidates: tf.data.Dataset,\n",
    "                 user_unique_values: dict,\n",
    "                 product_unique_ids: np.ndarray,\n",
    "                ):\n",
    "        super().__init__()\n",
    "        self.product_embedder = product_model\n",
    "        self.user_embedder = user_model\n",
    "        \n",
    "        self.user_features = user_unique_values.keys()\n",
    "        self.query_model = tf.keras.Sequential([\n",
    "                              user_model(user_unique_values),\n",
    "                              tf.keras.layers.Dense(32)\n",
    "                            ])\n",
    "        self.candidate_model = tf.keras.Sequential([\n",
    "                              product_model(product_unique_ids),\n",
    "                              tf.keras.layers.Dense(32)\n",
    "                            ])\n",
    "        # See https://www.tensorflow.org/recommenders/api_docs/python/tfrs/tasks/Retrieval\n",
    "        self.task = tfrs.tasks.Retrieval( # Loss function. Defaults to tf.keras.losses.CategoricalCrossentropy.\n",
    "            metrics=tfrs.metrics.FactorizedTopK( # TODO are we forced to use batch? - REMOVE for training\n",
    "                candidates=topk_candidates.batch(128).map(self.candidate_model), # dataset of candidate embeddings from which candidates should be retrieved (embedded)\n",
    "            ),\n",
    "        )\n",
    "    def get_user_tower(self):\n",
    "        return self.query_model\n",
    "    \n",
    "    def get_product_tower(self):\n",
    "        return self.candidate_model\n",
    "    \n",
    "    def compute_loss(self, features, training=False):\n",
    "        query_data = {feature_name: features[feature_name] for feature_name in self.user_features}\n",
    "        query_embeddings = self.query_model(query_data)\n",
    "        product_embeddings = self.candidate_model(features[\"Product_ID\"])\n",
    "        \n",
    "        # Retrieval call: https://www.tensorflow.org/recommenders/api_docs/python/tfrs/tasks/Retrieval\n",
    "        # \"The task will try to maximize the affinity of these query, candidate pairs while minimizing \n",
    "        # the affinity between the query and candidates belonging to other queries in the batch.\"\n",
    "        return self.task(query_embeddings=query_embeddings, \n",
    "                         candidate_embeddings=product_embeddings,\n",
    "                         compute_metrics=True, # disable for better performances\n",
    "                         candidate_ids = None\n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac270a07",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59ed0f49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorSpec(shape=(), dtype=tf.string, name=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Candidates to use for metrics\n",
    "tf_unique_products = tf.data.Dataset.from_tensor_slices(product_unique_values[\"Product_ID\"])\n",
    "tf_unique_products.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "477369e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BlackFridayModel(UserModel, ProductModel,\n",
    "                        topk_candidates = tf_unique_products,\n",
    "                        user_unique_values = user_unique_values,\n",
    "                        product_unique_ids = product_unique_values[\"Product_ID\"]\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eab609df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tf dataset\n",
    "tf.random.set_seed(42)\n",
    "train = tf.data.Dataset.from_tensor_slices(dict(df_train)) # [!] dict is important\n",
    "train = train.shuffle(100_000, seed=42, reshuffle_each_iteration=False)\n",
    "\n",
    "test = tf.data.Dataset.from_tensor_slices(dict(df_test))\n",
    "\n",
    "cached_train = train.shuffle(100_000).batch(2048) # TODO: double shuffle?\n",
    "cached_test = test.batch(4096).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8587fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a callback that saves the model's weights\n",
    "from datetime import datetime\n",
    "run_id = datetime.today().strftime('%Y%m%d%H%M%S')\n",
    "model_path = f\"./models/{run_id}/\"\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=model_path,\n",
    "                                                 save_weights_only=False,\n",
    "                                                 verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "9654116c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'Gender': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'Age': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'Occupation': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=string>, 'City_Category': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'Stay_In_Current_City_Years': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=string>, 'Marital_Status': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=string>}\n",
      "Consider rewriting this model with the Functional API.\n",
      "Creating layer for feature Gender\n",
      "Creating layer for feature Age\n",
      "Creating layer for feature Occupation\n",
      "Creating layer for feature City_Category\n",
      "Creating layer for feature Stay_In_Current_City_Years\n",
      "Creating layer for feature Marital_Status\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'Gender': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'Age': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'Occupation': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=string>, 'City_Category': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'Stay_In_Current_City_Years': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=string>, 'Marital_Status': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=string>}\n",
      "Consider rewriting this model with the Functional API.\n",
      "Creating layer for feature Gender\n",
      "Creating layer for feature Age\n",
      "Creating layer for feature Occupation\n",
      "Creating layer for feature City_Category\n",
      "Creating layer for feature Stay_In_Current_City_Years\n",
      "Creating layer for feature Marital_Status\n",
      "39/39 [==============================] - 34s 836ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0017 - factorized_top_k/top_5_categorical_accuracy: 0.0052 - factorized_top_k/top_10_categorical_accuracy: 0.0088 - factorized_top_k/top_50_categorical_accuracy: 0.0313 - factorized_top_k/top_100_categorical_accuracy: 0.0569 - loss: 15029.8940 - regularization_loss: 0.0000e+00 - total_loss: 15029.8940\n",
      "\n",
      "Epoch 00001: saving model to ./models/20210416153408/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fae8e1eb650>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))\n",
    "model.fit(cached_train, epochs=1, callbacks=cp_callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cccb8a1",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "681b9b26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow_recommenders.layers.factorized_top_k.BruteForce at 0x7fae8e1fde50>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify query embedder:\n",
    "index = tfrs.layers.factorized_top_k.BruteForce(model.get_user_tower())\n",
    "\n",
    "# Create the vector space\n",
    "index.index(tf_unique_products.batch(100).map(model.get_product_tower()), tf_unique_products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "ef614f73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'Gender': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'M'], dtype=object)>, 'Age': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'26-35'], dtype=object)>, 'Occupation': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'0'], dtype=object)>, 'City_Category': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'B'], dtype=object)>, 'Stay_In_Current_City_Years': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'4+'], dtype=object)>, 'Marital_Status': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'0'], dtype=object)>}\n",
      "Consider rewriting this model with the Functional API.\n",
      "Creating layer for feature Gender\n",
      "Creating layer for feature Age\n",
      "Creating layer for feature Occupation\n",
      "Creating layer for feature City_Category\n",
      "Creating layer for feature Stay_In_Current_City_Years\n",
      "Creating layer for feature Marital_Status\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(1, 10), dtype=float32, numpy=\n",
       " array([[0.83927035, 0.7979298 , 0.61289454, 0.56090105, 0.5586682 ,\n",
       "         0.55229056, 0.5514853 , 0.5412506 , 0.5301919 , 0.52725685]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 10), dtype=string, numpy=\n",
       " array([[b'P00221142', b'P00222442', b'P00218242', b'P00321342',\n",
       "         b'P00147642', b'P00077842', b'P00129142', b'P00229942',\n",
       "         b'P00043642', b'P00037342']], dtype=object)>)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get recommendations.\n",
    "input_data = {\n",
    "    \"Gender\": tf.constant([\"M\"]), # <-- [!] require list inside constant\n",
    "    \"Age\": tf.constant([\"26-35\"]),\n",
    "    \"Occupation\": tf.constant([\"0\"]),\n",
    "    \"City_Category\": tf.constant([\"B\"]),\n",
    "    \"Stay_In_Current_City_Years\": tf.constant([\"4+\"]),\n",
    "    \"Marital_Status\": tf.constant([\"0\"]),\n",
    "}\n",
    "index(input_data)\n",
    "# _, products = index(tf.constant([\"42\"]))\n",
    "# print(f\"Recommendations for user 42: {titles[0, :3]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57347def",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83d89a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserModel(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, unique_values:dict): # [Gender, [M, F]]\n",
    "        super().__init__()\n",
    "        \n",
    "        self.user_features = {}\n",
    "        for feature_name, unique_list in unique_values.items():\n",
    "            feature_layer = tf.keras.Sequential([\n",
    "                                tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "                                    vocabulary=unique_list, mask_token=None),\n",
    "                                    tf.keras.layers.Embedding(len(unique_list) + 1, 32),\n",
    "                            ], feature_name )\n",
    "            self.user_features[feature_name] = feature_layer\n",
    "            \n",
    "\n",
    "\n",
    "    def call(self, inputs):\n",
    "        layers_stack = []\n",
    "        for feature_name, feature_layer in self.user_features.items():\n",
    "            print(f\"Creating layer for feature {feature_name}\")\n",
    "            layer_valorized = feature_layer(inputs[feature_name])\n",
    "            layers_stack.append(layer_valorized)\n",
    "        return tf.concat(layers_stack, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a956a266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'Gender': <tf.Tensor: shape=(), dtype=string, numpy=b'M'>, 'Age': <tf.Tensor: shape=(), dtype=string, numpy=b'26-35'>, 'Occupation': <tf.Tensor: shape=(), dtype=string, numpy=b'0'>, 'City_Category': <tf.Tensor: shape=(), dtype=string, numpy=b'B'>, 'Stay_In_Current_City_Years': <tf.Tensor: shape=(), dtype=string, numpy=b'4+'>, 'Marital_Status': <tf.Tensor: shape=(), dtype=string, numpy=b'0'>}\n",
      "Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'Sequential' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-100-0e057fb1b57d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mmodel_user\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_user_tower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mmodel_user\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;31m# model_user.summary() # [!] da errore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1012\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'training'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1012\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-88-4796af393f39>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m# https://github.com/tensorflow/recommenders/blob/main/docs/examples/featurization.ipynb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         return tf.concat(self.feature_layer[\"Gender\"], \n\u001b[0m\u001b[1;32m     21\u001b[0m                          axis=1)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Sequential' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "input_data = {\n",
    "    \"Gender\": tf.constant(\"M\"),\n",
    "    \"Age\": tf.constant(\"26-35\"),\n",
    "    \"Occupation\": tf.constant(\"0\"),\n",
    "    \"City_Category\": tf.constant(\"B\"),\n",
    "    \"Stay_In_Current_City_Years\": tf.constant(\"4+\"),\n",
    "    \"Marital_Status\": tf.constant(\"0\"),\n",
    "}\n",
    "\n",
    "model_user = model.get_user_tower()\n",
    "model_user(input_data)\n",
    "# model_user.summary() # [!] da errore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8181c991",
   "metadata": {},
   "source": [
    "---\n",
    "# Test: train with less inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c135acce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserModelReduced(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self, unique_values:dict):\n",
    "        super().__init__()\n",
    "        unique_list = unique_values[\"Gender\"]\n",
    "        feature_layer = tf.keras.Sequential([\n",
    "                            tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "                                                            vocabulary=unique_list, \n",
    "                                                            mask_token=None),\n",
    "                            tf.keras.layers.Embedding(len(unique_list) + 1, 32),\n",
    "                        ], \n",
    "#             feature_name\n",
    "        )\n",
    "        self.feature_layer = feature_layer\n",
    "            \n",
    "\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # https://github.com/tensorflow/recommenders/blob/main/docs/examples/featurization.ipynb\n",
    "        return tf.concat(self.feature_layer[\"Gender\"], \n",
    "                         axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "03eb3020",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BlackFridayModel(UserModelReduced, ProductModel,\n",
    "                        topk_candidates = tf_unique_products,\n",
    "                        user_unique_values = user_unique_values,\n",
    "                        product_unique_ids = product_unique_values[\"Product_ID\"]\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "22d6a1dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'Gender': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'Age': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'Occupation': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=string>, 'City_Category': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'Stay_In_Current_City_Years': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=string>, 'Marital_Status': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=string>}\n",
      "Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n    /opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n        return step_function(self, iterator)\n    <ipython-input-70-4796af393f39>:21 call  *\n        axis=1)\n\n    TypeError: 'Sequential' object is not subscriptable\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-90-8539ceb10f6b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdagrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcached_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcp_callback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    869\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    724\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    725\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 726\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2967\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2968\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2969\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2970\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3204\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3205\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3206\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3208\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n    /opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n        return step_function(self, iterator)\n    <ipython-input-70-4796af393f39>:21 call  *\n        axis=1)\n\n    TypeError: 'Sequential' object is not subscriptable\n"
     ]
    }
   ],
   "source": [
    "# Create a callback that saves the model's weights\n",
    "from datetime import datetime\n",
    "run_id = datetime.today().strftime('%Y%m%d%H%M%S')\n",
    "\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=f\"./models/{run_id}/\",\n",
    "                                                 save_weights_only=False,\n",
    "                                                 verbose=1)\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))\n",
    "model.fit(cached_train, epochs=1, callbacks=cp_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96bc2365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# go deep\n",
    "model_user = model.get_user_tower()\n",
    "input_data = {\n",
    "    \"Gender\": tf.constant(\"M\"),\n",
    "}\n",
    "model_user(input_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2361ea",
   "metadata": {},
   "source": [
    "## Store\n",
    "**Note**\n",
    "- We need to store 2 things:\n",
    "    - The model (BlackFridayModel)\n",
    "    - The \"data embedded\" vector space "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba45003",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-3.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m65"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
