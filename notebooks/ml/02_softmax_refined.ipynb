{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adjusted-composer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tempfile\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_recommenders as tfrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dried-chart",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train shape:(78366, 12)\n",
      "df_test shape:(156733, 12)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from os.path import join\n",
    "\n",
    "dataset_parsed_path = \"/home/jupyter/mlspec-blackfriday/dataset/parsed/202104130952/\"\n",
    "train_path = join(dataset_parsed_path, \"train.csv\")\n",
    "test_path = join(dataset_parsed_path, \"eval.csv\")\n",
    "\n",
    "df_train=pd.read_csv(train_path)\n",
    "df_test=pd.read_csv(test_path)\n",
    "\n",
    "print(f\"df_train shape:{df_train.shape}\")\n",
    "print(f\"df_test shape:{df_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "olympic-driver",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User_ID       object\n",
      "Gender        object\n",
      "Product_ID    object\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Product_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1004732</td>\n",
       "      <td>M</td>\n",
       "      <td>P00235842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1003903</td>\n",
       "      <td>M</td>\n",
       "      <td>P00180442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1002340</td>\n",
       "      <td>M</td>\n",
       "      <td>P00303842</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User_ID Gender Product_ID\n",
       "0  1004732      M  P00235842\n",
       "1  1003903      M  P00180442\n",
       "2  1002340      M  P00303842"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = df_train[[\"User_ID\", \"Gender\", \"Product_ID\"]]\n",
    "df_train[\"User_ID\"] = df_train[\"User_ID\"].astype(str)\n",
    "df_train[\"Gender\"] = df_train[\"Gender\"].astype(str)\n",
    "df_train[\"Product_ID\"] = df_train[\"Product_ID\"].astype(str)\n",
    "\n",
    "print(df_train.dtypes)\n",
    "df_train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "international-conversation",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "injured-daisy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, dtype('O'), 2, 'M')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_gender = df_train[\"Gender\"].unique()\n",
    "type(unique_gender), unique_gender.dtype, len(unique_gender), unique_gender[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "normal-therapy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, dtype('O'), 5728, '1004732')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_user_id = df_train[\"User_ID\"].unique()\n",
    "type(unique_user_id), unique_user_id.dtype, len(unique_user_id), unique_user_id[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "integral-zimbabwe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, dtype('O'), 3250, 'P00235842')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_product_id = df_train[\"Product_ID\"].unique()\n",
    "type(unique_product_id), unique_product_id.dtype, len(unique_product_id), unique_product_id[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loaded-belarus",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "egyptian-space",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserModel(tf.keras.Model):\n",
    "  \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.user_embedding = tf.keras.Sequential([\n",
    "            tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "                vocabulary=unique_user_id, mask_token=None),\n",
    "            tf.keras.layers.Embedding(len(unique_user_id) + 1, 32),\n",
    "        ])\n",
    "\n",
    "        self.gender_embedding = tf.keras.Sequential([\n",
    "            tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "                    vocabulary=unique_gender, mask_token=None),\n",
    "            tf.keras.layers.Embedding(len(unique_gender) + 1, 32),\n",
    "        ])\n",
    "\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.concat([\n",
    "            self.user_embedding(inputs[\"User_ID\"]),\n",
    "            self.gender_embedding(inputs[\"Gender\"]),\n",
    "        ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "sacred-serbia",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProductModel(tf.keras.Model):\n",
    "  \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        max_tokens = 10_000\n",
    "\n",
    "        self.product_embedding = tf.keras.Sequential([\n",
    "          tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "              vocabulary=unique_product_id, mask_token=None),\n",
    "          tf.keras.layers.Embedding(len(unique_product_id) + 1, 32)\n",
    "        ])\n",
    "\n",
    "\n",
    "    def call(self, products_id):\n",
    "        return tf.concat([\n",
    "            self.product_embedding(products_id)\n",
    "        ], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greatest-syracuse",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "equal-express",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_products = tf.data.Dataset.from_tensor_slices(df_train[\"Product_ID\"].astype(str).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "optical-flower",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlackFridayModel(tfrs.models.Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.query_model = tf.keras.Sequential([\n",
    "          UserModel(),\n",
    "          tf.keras.layers.Dense(32)\n",
    "        ])\n",
    "        self.candidate_model = tf.keras.Sequential([\n",
    "          ProductModel(),\n",
    "          tf.keras.layers.Dense(32)\n",
    "        ])\n",
    "        self.task = tfrs.tasks.Retrieval(\n",
    "            metrics=tfrs.metrics.FactorizedTopK(\n",
    "                candidates=tf_products.batch(128).map(self.candidate_model), # dataset of candidate embeddings from which candidates should be retrieved (embedded)\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    def compute_loss(self, features, training=False):\n",
    "        query_embeddings = self.query_model({\n",
    "            \"User_ID\": features[\"User_ID\"],\n",
    "            \"Gender\": features[\"Gender\"],\n",
    "        })\n",
    "        product_embeddings = self.candidate_model(features[\"Product_ID\"])\n",
    "\n",
    "        return self.task(query_embeddings, product_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smart-diving",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "typical-judges",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'User_ID': TensorSpec(shape=(), dtype=tf.string, name=None),\n",
       " 'Gender': TensorSpec(shape=(), dtype=tf.string, name=None),\n",
       " 'Product_ID': TensorSpec(shape=(), dtype=tf.string, name=None)}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_dataset = tf.data.Dataset.from_tensor_slices(dict(df_train)) # dict missing!!!\n",
    "tf_dataset.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "italian-glenn",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "shuffled = tf_dataset.shuffle(100_000, seed=42, reshuffle_each_iteration=False)\n",
    "\n",
    "train = shuffled.take(80_000)\n",
    "test = shuffled.skip(80_000).take(20_000)\n",
    "\n",
    "cached_train = train.shuffle(100_000).batch(2048)\n",
    "cached_test = test.batch(4096).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "powerful-canal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'User_ID': TensorSpec(shape=(None,), dtype=tf.string, name=None),\n",
       "  'Gender': TensorSpec(shape=(None,), dtype=tf.string, name=None),\n",
       "  'Product_ID': TensorSpec(shape=(None,), dtype=tf.string, name=None)},\n",
       " {'User_ID': TensorSpec(shape=(None,), dtype=tf.string, name=None),\n",
       "  'Gender': TensorSpec(shape=(None,), dtype=tf.string, name=None),\n",
       "  'Product_ID': TensorSpec(shape=(None,), dtype=tf.string, name=None)})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cached_train.element_spec, cached_test.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "touched-details",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BlackFridayModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "unexpected-alberta",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "combined-feature",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'User_ID': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'Gender': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>}\n",
      "Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'User_ID': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'Gender': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>}\n",
      "Consider rewriting this model with the Functional API.\n",
      "39/39 [==============================] - 189s 5s/step - factorized_top_k/top_1_categorical_accuracy: 0.0080 - factorized_top_k/top_5_categorical_accuracy: 0.0080 - factorized_top_k/top_10_categorical_accuracy: 0.0080 - factorized_top_k/top_50_categorical_accuracy: 0.0087 - factorized_top_k/top_100_categorical_accuracy: 0.0098 - loss: 15003.7515 - regularization_loss: 0.0000e+00 - total_loss: 15003.7515\n",
      "Epoch 2/3\n",
      "39/39 [==============================] - 197s 5s/step - factorized_top_k/top_1_categorical_accuracy: 0.0014 - factorized_top_k/top_5_categorical_accuracy: 0.0014 - factorized_top_k/top_10_categorical_accuracy: 0.0016 - factorized_top_k/top_50_categorical_accuracy: 0.0035 - factorized_top_k/top_100_categorical_accuracy: 0.0061 - loss: 14760.6121 - regularization_loss: 0.0000e+00 - total_loss: 14760.6121\n",
      "Epoch 3/3\n",
      "39/39 [==============================] - 199s 5s/step - factorized_top_k/top_1_categorical_accuracy: 0.0015 - factorized_top_k/top_5_categorical_accuracy: 0.0017 - factorized_top_k/top_10_categorical_accuracy: 0.0025 - factorized_top_k/top_50_categorical_accuracy: 0.0093 - factorized_top_k/top_100_categorical_accuracy: 0.0171 - loss: 14120.1926 - regularization_loss: 0.0000e+00 - total_loss: 14120.1926\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fbfb82c5710>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(cached_train, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "wrong-performance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'User_ID': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'Gender': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>}\n",
      "Consider rewriting this model with the Functional API.\n",
      "39/39 [==============================] - 199s 5s/step - factorized_top_k/top_1_categorical_accuracy: 0.0179 - factorized_top_k/top_5_categorical_accuracy: 0.0193 - factorized_top_k/top_10_categorical_accuracy: 0.0237 - factorized_top_k/top_50_categorical_accuracy: 0.0481 - factorized_top_k/top_100_categorical_accuracy: 0.0691 - loss: 13208.8374 - regularization_loss: 0.0000e+00 - total_loss: 13208.8374\n",
      "\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/utils/generic_utils.py:583: RuntimeWarning: divide by zero encountered in log10\n",
      "  numdigits = int(np.log10(self.target)) + 1\n"
     ]
    },
    {
     "ename": "OverflowError",
     "evalue": "cannot convert float infinity to integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOverflowError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-8ae35473b3ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     cached_train, return_dict=True)[\"factorized_top_k/top_100_categorical_accuracy\"]\n\u001b[1;32m      3\u001b[0m test_accuracy = model.evaluate(\n\u001b[0;32m----> 4\u001b[0;31m     cached_test, return_dict=True)[\"factorized_top_k/top_100_categorical_accuracy\"]\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Top-100 accuracy (train): {train_accuracy:.2f}.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   1394\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1395\u001b[0m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1396\u001b[0;31m       \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1398\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_test_end\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m    560\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_supports_tf_logs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m         \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnumpy_logs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Only convert once.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_test_end\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m   1033\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_called_in_fit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1035\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_finalize_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_test_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1036\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_predict_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_finalize_progbar\u001b[0;34m(self, logs, counter)\u001b[0m\n\u001b[1;32m   1094\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcounter\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1096\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1097\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, current, values, finalize)\u001b[0m\n\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m         \u001b[0mnumdigits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog10\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m         \u001b[0mbar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'%'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumdigits\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'd/%d ['\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcurrent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m         \u001b[0mprog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOverflowError\u001b[0m: cannot convert float infinity to integer"
     ]
    }
   ],
   "source": [
    "train_accuracy = model.evaluate(\n",
    "    cached_train, return_dict=True)[\"factorized_top_k/top_100_categorical_accuracy\"]\n",
    "test_accuracy = model.evaluate(\n",
    "    cached_test, return_dict=True)[\"factorized_top_k/top_100_categorical_accuracy\"]\n",
    "    \n",
    "print(f\"Top-100 accuracy (train): {train_accuracy:.2f}.\")\n",
    "print(f\"Top-100 accuracy (test): {test_accuracy:.2f}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amended-sharing",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "julian-monroe",
   "metadata": {},
   "source": [
    "##### model.fit(cached_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "improving-flexibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracy = model.evaluate(\n",
    "    cached_train, return_dict=True)[\"factorized_top_k/top_100_categorical_accuracy\"]\n",
    "test_accuracy = model.evaluate(\n",
    "    cached_test, return_dict=True)[\"factorized_top_k/top_100_categorical_accuracy\"]\n",
    "    \n",
    "print(f\"Top-100 accuracy (train): {train_accuracy:.2f}.\")\n",
    "print(f\"Top-100 accuracy (test): {test_accuracy:.2f}.\")"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-3.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m65"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
